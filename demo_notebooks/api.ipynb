{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API demo\n",
    "this is a general notebook for demonstrating the variations available with the circuit pruner api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_explorer/env/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_explorer/env/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_explorer/env/lib/python3.7/site-packages/torch/cuda/__init__.py:132: UserWarning: \n",
      "    Found GPU3 Tesla K40c which is of cuda capability 3.5.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, minor, min_arch // 10, min_arch % 10))\n"
     ]
    }
   ],
   "source": [
    "#pick a device\n",
    "device = 'cuda:0'\n",
    "\n",
    "#pick a model, any pytorch model should do, but well load in our sparsity regularized alexnet model\n",
    "from circuit_explorer.utils import load_config\n",
    "config_file = '../configs/alexnet_sparse_config.py'\n",
    "config = load_config(config_file)\n",
    "model = config.model\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#alternative\n",
    "#from torchvision import models\n",
    "#model = models.vgg11(pretrained = True)\n",
    "\n",
    "\n",
    "from circuit_explorer.utils import convert_relu_layers\n",
    "convert_relu_layers(model)  #make relus not inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers that can be used a as target for pruning can be identified with the line below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['', 'features', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'avgpool', 'classifier', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from circuit_explorer.utils import get_layers_from_model\n",
    "\n",
    "all_layers = get_layers_from_model(model)\n",
    "all_layers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all keys in the above dictionary can be used to specify a target layer for pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify target feature with unit and layer\n",
    "\n",
    "import torch\n",
    "\n",
    "layer = 'classifier.6'   #key from 'all_layers' dictionary \n",
    "unit = 1                # single unit feature target, the 2nd dimension (0 is 1st) in the layers space\n",
    "\n",
    "#OR UNCOMMENT BELOW\n",
    "#unit = torch.rand(256) # random direction feature in layers latent space ('features.10' is 256 dimensional)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataloader\n",
    "our api uses pytorch dataloaders (torch.utils.data.DataLoader) to specify images to use for pruning.\n",
    "Any DataLoader should do, but we provide some useful data classes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from circuit_explorer.data_loading import rank_image_data, single_image_data\n",
    "\n",
    "#if using snip scoring (weight-wise) batch_size must be 1\n",
    "#batch_size = 1\n",
    "\n",
    "#for other scoring batch-size can be larger\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True, 'sampler':None} if 'cuda' in device else {}\n",
    "\n",
    "dataloader = DataLoader(rank_image_data('../image_data/imagenet_2/',class_folders=True),\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        **kwargs)\n",
    "\n",
    "\n",
    "##OR UNCOMMENT BELOW to score with respect to a single image, we provide a simple dataloader class\n",
    "# image_file_path = '../image_data/imagenet_2/Egyptian_cat/Egyptian_cat_10034.JPEG'\n",
    "# dataloader = DataLoader(single_image_data(image_file_path),\n",
    "#                         batch_size=1,\n",
    "#                         shuffle=False,\n",
    "#                         **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score\n",
    "get saliency scores to target feature from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features.0',\n",
       "              tensor([0.1978, 0.2926, 0.4995, 0.3185, 0.4526, 0.9562, 0.6282, 0.0485, 0.6232,\n",
       "                      0.1304, 0.5631, 0.6069, 0.5412, 0.4715, 0.5202, 0.0288, 0.4770, 0.8156,\n",
       "                      0.3955, 0.0529, 0.2566, 0.7679, 0.2396, 0.4641, 0.3726, 0.1949, 0.1888,\n",
       "                      0.1622, 0.3785, 0.2813, 0.2833, 0.1786, 0.4868, 0.3146, 0.3973, 0.2045,\n",
       "                      0.3663, 1.0000, 0.4636, 0.2652, 0.2689, 0.4933, 0.4113, 0.3913, 0.2284,\n",
       "                      0.1669, 0.0759, 0.8656, 0.2756, 0.4831, 0.8277, 0.1296, 0.7697, 0.2644,\n",
       "                      0.1156, 0.5357, 0.7196, 0.6365, 0.1269, 0.4928, 0.0000, 0.1693, 0.6796,\n",
       "                      0.2576])),\n",
       "             ('features.3',\n",
       "              tensor([0.4617, 0.4942, 0.5675, 0.6108, 0.0678, 0.2549, 0.1487, 0.1510, 0.5193,\n",
       "                      0.4936, 0.2084, 1.0000, 0.4757, 0.3723, 0.3122, 0.4063, 0.1632, 0.1673,\n",
       "                      0.0030, 0.4196, 0.3597, 0.7169, 0.8428, 0.2384, 0.3749, 0.5228, 0.0708,\n",
       "                      0.4344, 0.0743, 0.3871, 0.3729, 0.7847, 0.1333, 0.2193, 0.3860, 0.4154,\n",
       "                      0.2267, 0.4103, 0.2515, 0.2809, 0.6100, 0.2003, 0.3017, 0.3432, 0.1650,\n",
       "                      0.2460, 0.3284, 0.4056, 0.3448, 0.3504, 0.3093, 0.0881, 0.4408, 0.2311,\n",
       "                      0.5689, 0.0734, 0.2710, 0.2314, 0.3542, 0.1094, 0.3585, 0.2679, 0.4090,\n",
       "                      0.0588, 0.1180, 0.3144, 0.3653, 0.4856, 0.6664, 0.7922, 0.2677, 0.4926,\n",
       "                      0.1504, 0.0922, 0.4261, 0.2382, 0.5680, 0.3603, 0.2321, 0.2435, 0.4535,\n",
       "                      0.2045, 0.2162, 0.4127, 0.2845, 0.3259, 0.3109, 0.2647, 0.3943, 0.2185,\n",
       "                      0.3324, 0.2692, 0.2241, 0.1494, 0.4588, 0.3093, 0.3015, 0.2366, 0.4426,\n",
       "                      0.2372, 0.4252, 0.2960, 0.3314, 0.0657, 0.3428, 0.3973, 0.3147, 0.8695,\n",
       "                      0.3909, 0.3055, 0.2046, 0.3784, 0.5390, 0.4176, 0.3640, 0.1492, 0.5333,\n",
       "                      0.2847, 0.1526, 0.5639, 0.3079, 0.0000, 0.4559, 0.1440, 0.2797, 0.4074,\n",
       "                      0.1168, 0.2632, 0.2976, 0.5033, 0.2956, 0.3075, 0.2726, 0.4457, 0.4582,\n",
       "                      0.4625, 0.4969, 0.4142, 0.4496, 0.1704, 0.3179, 0.4196, 0.2207, 0.2121,\n",
       "                      0.1976, 0.1785, 0.4654, 0.4569, 0.2524, 0.4620, 0.3274, 0.1999, 0.3027,\n",
       "                      0.4580, 0.6347, 0.4958, 0.1311, 0.1797, 0.3241, 0.5799, 0.1487, 0.5691,\n",
       "                      0.2234, 0.3878, 0.1620, 0.1316, 0.2986, 0.4672, 0.5023, 0.3918, 0.4153,\n",
       "                      0.6134, 0.3745, 0.0471, 0.0520, 0.1247, 0.2581, 0.2313, 0.1343, 0.0468,\n",
       "                      0.6776, 0.3693, 0.5367, 0.3335, 0.3016, 0.1889, 0.4123, 0.1304, 0.3912,\n",
       "                      0.3497, 0.1143, 0.1034])),\n",
       "             ('features.6',\n",
       "              tensor([0.2998, 0.4497, 0.2399, 0.1169, 0.2954, 0.3149, 0.2935, 0.2031, 0.2507,\n",
       "                      0.7283, 0.3542, 0.2442, 0.4344, 0.2836, 0.7372, 0.2028, 0.3570, 0.3736,\n",
       "                      0.5077, 0.1474, 0.4395, 0.4920, 0.4102, 0.2791, 0.1822, 0.2804, 0.1792,\n",
       "                      0.3229, 0.1475, 0.2713, 0.3170, 0.4150, 0.4982, 0.3044, 0.4265, 0.2961,\n",
       "                      0.4933, 0.2916, 0.3433, 0.3548, 0.2183, 0.4242, 0.5254, 0.1670, 0.3526,\n",
       "                      0.3690, 0.2630, 0.2901, 0.4457, 0.2347, 0.4195, 0.1651, 0.1741, 0.3195,\n",
       "                      0.3381, 0.3409, 0.5185, 0.1658, 0.3064, 0.1227, 0.2866, 0.4893, 0.1132,\n",
       "                      0.5176, 0.4175, 0.1298, 0.5021, 0.2680, 0.5347, 0.1810, 0.3475, 0.1938,\n",
       "                      0.1913, 0.2223, 0.2552, 0.5410, 0.2221, 0.2915, 0.3237, 0.1350, 0.2780,\n",
       "                      0.2645, 0.3350, 0.1172, 0.3169, 0.1431, 0.4825, 0.5614, 0.2400, 0.2081,\n",
       "                      0.1956, 0.3069, 0.5386, 0.2924, 0.2700, 0.3570, 0.3121, 0.1779, 0.2780,\n",
       "                      0.1690, 0.2734, 0.1095, 0.1694, 0.2312, 0.6958, 0.3178, 0.1730, 0.3561,\n",
       "                      0.1224, 0.1534, 0.2495, 0.1492, 0.3292, 0.2773, 0.4258, 0.3850, 0.2915,\n",
       "                      0.1861, 0.6273, 0.4251, 0.4137, 0.2353, 0.3739, 0.2833, 0.5664, 0.2074,\n",
       "                      0.5806, 0.1433, 0.1851, 0.3311, 0.1964, 0.2986, 0.2121, 0.4663, 0.1377,\n",
       "                      0.2032, 0.4299, 0.2550, 0.3228, 0.4208, 0.2614, 0.2672, 0.5996, 0.4292,\n",
       "                      0.3614, 0.2646, 0.4675, 0.5217, 0.3443, 0.4312, 0.5027, 0.3506, 0.2128,\n",
       "                      0.3480, 0.3114, 0.2982, 0.3058, 0.1844, 0.0964, 0.3299, 0.2908, 0.1469,\n",
       "                      0.3501, 0.2910, 0.1195, 0.1524, 0.1860, 0.2389, 0.1904, 0.5706, 0.1081,\n",
       "                      0.1999, 0.1469, 0.2426, 0.3704, 0.0827, 0.3505, 0.3374, 0.0513, 0.1310,\n",
       "                      0.4500, 0.1744, 0.1875, 0.5565, 0.1524, 0.2499, 0.5003, 0.4746, 0.2677,\n",
       "                      0.2036, 0.3972, 0.5081, 0.1042, 0.2343, 0.3797, 0.3044, 0.3324, 0.2852,\n",
       "                      0.3953, 0.2276, 0.2944, 0.3242, 0.3107, 0.1992, 0.2083, 0.0855, 0.2583,\n",
       "                      0.1543, 0.3373, 0.2806, 0.2839, 0.4440, 0.2335, 0.4113, 0.3607, 0.2914,\n",
       "                      0.1598, 0.2160, 0.6957, 0.2667, 0.4831, 0.1894, 0.4342, 0.3762, 0.6920,\n",
       "                      0.4516, 0.2424, 0.3932, 0.2728, 0.3068, 0.2634, 0.2197, 0.2997, 1.0000,\n",
       "                      0.1836, 0.4850, 0.1390, 0.2048, 0.1634, 0.3743, 0.6559, 0.1631, 0.2914,\n",
       "                      0.6504, 0.5596, 0.0970, 0.2227, 0.1238, 0.2054, 0.2477, 0.8160, 0.2244,\n",
       "                      0.2960, 0.2570, 0.2646, 0.1048, 0.0997, 0.3492, 0.2667, 0.4182, 0.3711,\n",
       "                      0.9033, 0.2955, 0.1754, 0.2391, 0.2198, 0.1612, 0.3463, 0.4806, 0.1914,\n",
       "                      0.2825, 0.3524, 0.1873, 0.3338, 0.2342, 0.5648, 0.2306, 0.2874, 0.4394,\n",
       "                      0.5623, 0.2428, 0.3261, 0.1290, 0.2282, 0.2379, 0.2046, 0.3569, 0.2807,\n",
       "                      0.1768, 0.3399, 0.2256, 0.2692, 0.4093, 0.3692, 0.3795, 0.3148, 0.1884,\n",
       "                      0.3700, 0.2241, 0.0882, 0.3864, 0.0466, 0.3777, 0.3972, 0.3472, 0.3676,\n",
       "                      0.1209, 0.3746, 0.1458, 0.2477, 0.2656, 0.2094, 0.2465, 0.3678, 0.2816,\n",
       "                      0.2535, 0.2737, 0.2745, 0.3023, 0.3677, 0.2738, 0.2952, 0.5096, 0.2590,\n",
       "                      0.3964, 0.1723, 0.2310, 0.4896, 0.1017, 0.1217, 0.5507, 0.0651, 0.2558,\n",
       "                      0.4714, 0.1808, 0.1598, 0.1889, 0.4134, 0.2333, 0.4214, 0.2534, 0.6685,\n",
       "                      0.4351, 0.6078, 0.2064, 0.2426, 0.1910, 0.1580, 0.3319, 0.4063, 0.4524,\n",
       "                      0.1853, 0.2386, 0.1727, 0.1887, 0.3858, 0.3952, 0.3731, 0.2439, 0.0000,\n",
       "                      0.4037, 0.5000, 0.3648, 0.2392, 0.3871, 0.3559, 0.3013, 0.2594, 0.2803,\n",
       "                      0.1440, 0.2326, 0.2634, 0.1280, 0.2372, 0.4132, 0.6271, 0.2448, 0.2173,\n",
       "                      0.2874, 0.3800, 0.7869, 0.3417, 0.2734, 0.6549])),\n",
       "             ('features.8',\n",
       "              tensor([0.6525, 0.3735, 0.5077, 0.4450, 0.4266, 0.3033, 0.5480, 0.3808, 0.5204,\n",
       "                      0.4174, 0.2724, 0.5154, 0.4623, 0.3263, 0.4746, 0.4872, 0.1864, 0.3990,\n",
       "                      0.4087, 0.5258, 0.1267, 0.4634, 0.1799, 0.0424, 0.1687, 0.3408, 0.0000,\n",
       "                      0.5881, 0.5728, 0.5935, 0.3681, 0.1772, 0.3212, 0.4544, 0.2891, 0.6587,\n",
       "                      0.3769, 0.6150, 0.3972, 0.4478, 0.1871, 0.7613, 0.3786, 0.7279, 0.2287,\n",
       "                      0.1671, 0.3829, 0.8885, 0.3540, 0.1994, 0.2357, 0.3374, 0.2778, 0.2161,\n",
       "                      0.3876, 0.3222, 0.2071, 0.0844, 0.3074, 0.2110, 0.3178, 1.0000, 0.0704,\n",
       "                      0.1456, 0.4104, 0.1242, 0.5772, 0.2210, 0.3280, 0.1036, 0.2087, 0.3111,\n",
       "                      0.3983, 0.6638, 0.3217, 0.5465, 0.6406, 0.2459, 0.1204, 0.3104, 0.3510,\n",
       "                      0.4708, 0.2864, 0.3266, 0.3601, 0.2481, 0.3101, 0.4395, 0.3322, 0.0512,\n",
       "                      0.2372, 0.5398, 0.4086, 0.1680, 0.4112, 0.0117, 0.2117, 0.3131, 0.3454,\n",
       "                      0.5718, 0.4293, 0.3502, 0.3557, 0.4873, 0.4825, 0.1626, 0.2141, 0.4357,\n",
       "                      0.2263, 0.4679, 0.4258, 0.0712, 0.1206, 0.4612, 0.1552, 0.2072, 0.2022,\n",
       "                      0.4834, 0.3694, 0.3280, 0.6614, 0.3094, 0.2354, 0.3058, 0.3687, 0.0419,\n",
       "                      0.2081, 0.0843, 0.4028, 0.3629, 0.2151, 0.2444, 0.3174, 0.4278, 0.1686,\n",
       "                      0.4269, 0.5192, 0.2959, 0.3220, 0.3185, 0.3699, 0.3112, 0.6554, 0.8058,\n",
       "                      0.8211, 0.3451, 0.4151, 0.5108, 0.3213, 0.3098, 0.0110, 0.3317, 0.5785,\n",
       "                      0.3011, 0.1444, 0.4173, 0.3185, 0.9143, 0.3919, 0.2679, 0.2586, 0.4308,\n",
       "                      0.0808, 0.2532, 0.2768, 0.3502, 0.2995, 0.8461, 0.3361, 0.0798, 0.1135,\n",
       "                      0.2124, 0.2539, 0.1332, 0.3258, 0.3463, 0.2071, 0.2164, 0.5891, 0.3193,\n",
       "                      0.2867, 0.3360, 0.2123, 0.2524, 0.3537, 0.5828, 0.3317, 0.2996, 0.3805,\n",
       "                      0.0962, 0.1967, 0.6991, 0.0824, 0.7244, 0.2945, 0.2628, 0.2525, 0.3571,\n",
       "                      0.6332, 0.4766, 0.1843, 0.2894, 0.1723, 0.3898, 0.2054, 0.3154, 0.2461,\n",
       "                      0.0658, 0.3373, 0.0445, 0.3740, 0.2740, 0.1910, 0.4058, 0.5543, 0.2336,\n",
       "                      0.3866, 0.6508, 0.3578, 0.4202, 0.6318, 0.1941, 0.0859, 0.2556, 0.4180,\n",
       "                      0.4315, 0.1041, 0.3698, 0.4797, 0.2167, 0.5494, 0.2503, 0.4781, 0.3823,\n",
       "                      0.4685, 0.2286, 0.0724, 0.2078, 0.4783, 0.1967, 0.3327, 0.3017, 0.7373,\n",
       "                      0.5535, 0.2266, 0.3381, 0.2465, 0.6455, 0.3480, 0.3456, 0.4083, 0.1815,\n",
       "                      0.4464, 0.1529, 0.7390, 0.2859])),\n",
       "             ('features.10',\n",
       "              tensor([0.6692, 0.1852, 0.2662, 0.3683, 0.2393, 0.3327, 0.1198, 0.1889, 0.2108,\n",
       "                      0.1214, 0.3626, 0.1431, 0.1270, 0.1496, 0.0957, 0.1808, 0.3353, 0.0935,\n",
       "                      0.1115, 0.1267, 0.1382, 0.2098, 0.1311, 0.1442, 0.2882, 0.3410, 0.2074,\n",
       "                      1.0000, 0.1422, 0.2764, 0.0855, 0.2586, 0.1906, 0.2247, 0.3531, 0.2930,\n",
       "                      0.2412, 0.1322, 0.0837, 0.4024, 0.2042, 0.2116, 0.3573, 0.4411, 0.1575,\n",
       "                      0.3271, 0.3322, 0.3134, 0.3342, 0.1070, 0.3346, 0.1865, 0.2901, 0.2857,\n",
       "                      0.1748, 0.1317, 0.6245, 0.3371, 0.2426, 0.0180, 0.1259, 0.4390, 0.1921,\n",
       "                      0.2143, 0.0096, 0.1206, 0.1558, 0.5784, 0.2981, 0.3076, 0.1735, 0.2309,\n",
       "                      0.1013, 0.1505, 0.1155, 0.1233, 0.4639, 0.1721, 0.2033, 0.3789, 0.1088,\n",
       "                      0.2734, 0.1600, 0.4285, 0.2617, 0.1813, 0.1318, 0.4916, 0.1764, 0.1244,\n",
       "                      0.1794, 0.4457, 0.1515, 0.1605, 0.1459, 0.2780, 0.2533, 0.1350, 0.0875,\n",
       "                      0.4164, 0.3605, 0.1095, 0.2167, 0.2128, 0.1909, 0.1908, 0.2032, 0.1319,\n",
       "                      0.1895, 0.0000, 0.1734, 0.1633, 0.3636, 0.1517, 0.2810, 0.0079, 0.1286,\n",
       "                      0.1546, 0.1374, 0.0715, 0.1494, 0.1881, 0.3920, 0.1487, 0.2183, 0.8213,\n",
       "                      0.5840, 0.3265, 0.0054, 0.0397, 0.0431, 0.2052, 0.1601, 0.0905, 0.3630,\n",
       "                      0.1304, 0.2626, 0.1485, 0.2339, 0.4118, 0.1476, 0.1848, 0.1388, 0.2163,\n",
       "                      0.1814, 0.3777, 0.2539, 0.3155, 0.2793, 0.4083, 0.2007, 0.1459, 0.2220,\n",
       "                      0.4953, 0.1758, 0.2707, 0.2204, 0.1772, 0.4616, 0.1508, 0.1420, 0.0394,\n",
       "                      0.1290, 0.0676, 0.2879, 0.1782, 0.5793, 0.3063, 0.1595, 0.2347, 0.1321,\n",
       "                      0.4236, 0.2823, 0.9993, 0.1548, 0.1908, 0.0092, 0.2443, 0.1391, 0.2051,\n",
       "                      0.2110, 0.3130, 0.2591, 0.2036, 0.0444, 0.4233, 0.1554, 0.0852, 0.2560,\n",
       "                      0.2025, 0.4340, 0.1711, 0.1462, 0.0077, 0.2909, 0.3854, 0.0253, 0.1412,\n",
       "                      0.2931, 0.2030, 0.2652, 0.2165, 0.1954, 0.1576, 0.2929, 0.1376, 0.1908,\n",
       "                      0.2224, 0.2132, 0.4430, 0.1127, 0.1551, 0.1842, 0.2448, 0.3118, 0.2712,\n",
       "                      0.1760, 0.0614, 0.1931, 0.1664, 0.2929, 0.2531, 0.0876, 0.1856, 0.2903,\n",
       "                      0.1353, 0.1798, 0.1249, 0.8413, 0.0899, 0.2418, 0.1127, 0.1817, 0.5366,\n",
       "                      0.2352, 0.0677, 0.1598, 0.2314, 0.2249, 0.1704, 0.1463, 0.1565, 0.1671,\n",
       "                      0.2098, 0.2018, 0.1365, 0.3982, 0.1413, 0.1281, 0.1683, 0.1876, 0.1465,\n",
       "                      0.3288, 0.1847, 0.1462, 0.1032])),\n",
       "             ('classifier.1',\n",
       "              tensor([0.2420, 0.2971, 0.2435,  ..., 0.3219, 0.4867, 0.3502])),\n",
       "             ('classifier.4',\n",
       "              tensor([0.1827, 0.1895, 0.0234,  ..., 0.1448, 0.2034, 0.0758]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#general actgrad scoring\n",
    "from circuit_explorer.score import actgrad_score, structure_scores, minmax_norm_scores\n",
    "scores = actgrad_score(model,dataloader,layer,unit)\n",
    "scores = structure_scores(scores, model, structure='filters')   #structure from  ['kernels','filters']\n",
    "scores = minmax_norm_scores(scores) \n",
    "\n",
    "# #kernel-wise\n",
    "# from circuit_explorer.score import actgrad_kernel_score\n",
    "# scores = actgrad_kernel_score(model,dataloader,layer,unit)\n",
    "\n",
    "# #filter-wise\n",
    "# from circuit_explorer.score import actgrad_filter_score\n",
    "# scores = actgrad_filter_score(model,dataloader,layer,unit)\n",
    "\n",
    "# #weight-wise\n",
    "# from circuit_explorer.score import snip_score, structured scores\n",
    "# scores = snip_score(model,dataloader,layer,unit)\n",
    "    # #convert weight-wise scores to structured scores\n",
    "# scores = structure_scores(scores, model, structure='kernels')   #structure from  ['kernels','filters']\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mask\n",
    "mask low scoring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_explorer.mask import mask_from_scores, apply_mask, setup_net_for_mask\n",
    "\n",
    "sparsity = .1\n",
    "mask = mask_from_scores(scores,sparsity = sparsity, model = model,unit=unit,target_layer=layer)\n",
    "apply_mask(model,mask) #model now has a weight mask inserted\n",
    "\n",
    "#reset mask in model to all ones\n",
    "#setup_net_for_mask(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 192, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[6].weight_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuit_explorer",
   "language": "python",
   "name": "circuit_explorer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
